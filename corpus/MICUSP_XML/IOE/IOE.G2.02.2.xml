<TEI.2><teiHeader><fileDesc><titleStmt><title>Convergence of Simulation-Based Policy Iteration</title><author>anonymized</author></titleStmt><wordcount>841</wordcount><editionStmt><edition>Version 1.0</edition></editionStmt><extent>insert_extent</extent><publicationStmt><idno>IOE.G2.02.2</idno><publisher>The University of Michigan</publisher><pubPlace>Ann Arbor, Michigan, USA</pubPlace><date>2007</date><availability><p>The MICUSP project is owned by the Regents of the University of Michigan, who hold the copyright. The database has been developed by the English Language Institute. The original text submissions are stored electronically in the English Language Institute and may be consulted by bona fide researchers under special arrangements. The database is available by password on the World Wide Web for study, teaching and research purposes. Copies of the text files may be distributed, as long as either this statement of availability or the citation given below appears in the text. However, if any portion of this material is to be used for commercial purposes, such as for textbooks or tests, permission must be obtained in advance and a license fee may be required. For further information about copyright permissions, please inquire at micusp@umich.edu.</p><p>The recommended citation for MICASE is: Ädel, A., J. M. Swales, and J. Sielaff. (2007) The Michigan Corpus of Upper-level Student Papers. Ann Arbor, MI: The Regents of the University of Michigan.</p></availability></publicationStmt><seriesStmt><title>The Michigan Corpus of Upper-level Student Papers (MICUSP)</title></seriesStmt><sourceDesc><p>This document derives from an unpublished, student-authored paper contributed in electronic format.</p></sourceDesc></fileDesc><encodingDesc><projectDesc><p>For information on corpus compilation and encoding practices, see the MICUSP Handbook.</p></projectDesc><classDecl><taxonomy><category><catDesc>departments</catDesc><category id="BIO"><catDesc>Biology</catDesc></category><category id="CEE"><catDesc>Civil and Environmental Engineering</catDesc></category><category id="CLS"><catDesc>Classical Studies</catDesc></category><category id="ECO"><catDesc>Economics</catDesc></category><category id="EDU"><catDesc>Education</catDesc></category><category id="ENG"><catDesc>English</catDesc></category><category id="IOE"><catDesc>Industrial and Operational Engineering</catDesc></category><category id="LIN"><catDesc>Linguistics</catDesc></category><category id="MEC"><catDesc>Mechanical Engineering</catDesc></category><category id="NRE"><catDesc>Natural Resources</catDesc></category><category id="NUR"><catDesc>Nursing</catDesc></category><category id="PHI"><catDesc>Philosophy</catDesc></category><category id="PHY"><catDesc>Physics</catDesc></category><category id="POL"><catDesc>Political Science</catDesc></category><category id="PSY"><catDesc>Psychology</catDesc></category><category id="SOC"><catDesc>Sociology</catDesc></category></category><category><catDesc>student levels</catDesc><category id="G0"><catDesc>senior undergraduate</catDesc></category><category id="G1"><catDesc>first-year graduate</catDesc></category><category id="G2"><catDesc>second-year graduate</catDesc></category><category id="G3"><catDesc>third-year graduate and up</catDesc></category></category><category><catDesc>student-reported text types</catDesc><category id="CaseStudy"><catDesc>case study</catDesc></category><category id="Critique"><catDesc>critique</catDesc></category><category id="LiteratureReview"><catDesc>literature review</catDesc></category><category id="ResearchProposal"><catDesc>research proposal</catDesc></category><category id="ResponsePaper"><catDesc>response paper</catDesc></category><category id="TechnicalOrLabReport"><catDesc>technical report or lab report</catDesc></category><category id="TermPaper"><catDesc>term paper</catDesc></category><category id="OtherTextType"><catDesc>other</catDesc></category></category><category><catDesc>approximate preparation times</catDesc><category id="OneToThreeDays"><catDesc>1-3 days</catDesc></category><category id="FourToTenDays"><catDesc>4-10 days</catDesc></category><category id="TwoToThreeWeeks"><catDesc>2-3 weeks</catDesc></category><category id="ThreeToSixWeeks"><catDesc>3-6 weeks</catDesc></category><category id="OneFullSemester"><catDesc>one full semester</catDesc></category></category><category><catDesc>sources of feedback</catDesc><category id="NoFeedback"><catDesc>no feedback from others</catDesc></category><category id="PrimaryInstructor"><catDesc>primary course instructor</catDesc></category><category id="GSI"><catDesc>Graduate Student Instructor (teaching assistant)</catDesc></category><category id="WritingTutor"><catDesc>writing tutor</catDesc></category><category id="FriendOrClassmate"><catDesc>friend or classmate</catDesc></category><category id="OtherFeedback"><catDesc>other</catDesc></category></category></taxonomy></classDecl></encodingDesc><profileDesc><creation>Paper submitted to instructor in Oct 2004</creation><particDesc><person id="P218" sex="m" age="TwentyFourToThirty"><affiliation>IOE</affiliation><firstLang>English</firstLang><dominantLang>English</dominantLang><englishInPrimarySchool value="YES"/><englishInSecondarySchool value="YES"/><englishInUndergraduate value="YES"/></person></particDesc><textClass><catRef target="IOE G2 Essay LiteratureReview FourToTenDays NoFeedback"><classification><primary>Argumentative Essay</primary><secondary/></classification><classification><primary>Argumentative Essay</primary><secondary>Response Paper</secondary></classification><features/></catRef></textClass></profileDesc><revisionDesc><change><date>2008-03-28</date><respStmt><name>Geoffrey Ho</name><resp>coder</resp></respStmt><item>manual adjustment of tags</item></change><change><date>2008-08-04</date><respStmt><name>Beilei Zhang</name><resp>coder</resp></respStmt><item>manual adjustment of tags</item></change><change><date>2007-05-22</date><respStmt><name>Gregory Garretson</name><resp>programmer</resp></respStmt><item>initial (automated) encoding in XML</item></change></revisionDesc></teiHeader><text><body><div type="opener"><head>Convergence of Simulation-Based Policy Iteration</head><p/></div><div type="main"><p>	In <i type="title">Convergence of Simulation-Based Policy Iteration</i> (SBPI), Cooper, Henderson and Lewis are able to derive conditions under which a novel algorithm for computing optimal policies for Markov decision processes (MDPs).  They point out that SBPI, originally suggested by Bertsekas and further developed by Cao, works similarly to the modified policy iteration algorithm (MPIA) and to the actor critic algorithm.  It is therefore expected to converge faster than by the value iteration algorithm, yet the exact conditions under which SBPI converges had not been developed.  That places the results of this paper in a position of great importance, and its applicability is shown in the description of methods to converge to estimators via simulation.  These estimators can then be used to ensure the <q>almost-sure</q> convergence of SBPI.</p><p>	Let us begin by comparing MPIA and SBPI.  It is important to point out that the model used in this paper is the <i type="term">average-reward model</i>, not the <i type="term">discounted reward model</i> as studied thus far in IOE 512.  This distinction required that I understand new measures:</p><list><item>• The <i>gain</i>, <gap desc="formula"/>, or the long-run average reward</item><item>• The <i>bias</i>, <gap desc="formula"/></item></list><p>for a policy <gap desc="formula"/>  given that the system started in state <i>x</i>.  Puterman (p. 338) defines the bias as <q type="quote">the expected total difference between the reward and the stationary reward.</q>  These two definitions are key to understanding SBPI, whose algorithm proceeds as follows:</p><list><item>1. (Initialization)  Choose a sequence <gap desc="formula"/> and a decision rule <i>d0</i>.  Let <i>j</i> = 0.</item><item>2. (Policy Evaluation Approximation)  Obtain an estimate of the solution to the AEE <gap desc="formula"/>  for the decision rule dj.</item><item>3. (Policy Improvement)  Using our current estimate, find a decision rule dj+1 that satisfies <gap desc="formula"/>  for each <gap desc="formula"/>, setting <gap desc="formula"/> whenever possible.</item><item>4. (Iteration)  Let <gap desc="formula"/> and return to step 2.</item></list><p>Since the AEE (<i type="term">average evaluation equations</i>) are satisfied by a unique vector h, if we can find a solution (<i>g</i>, <i>h</i>) that satisfies <gap desc="formula"/>  the <i type="term">average optimality equations</i> (AOE), then <i>g = g*</i> and we have found the set of optimal policies<gap desc="formula"/>.  The SBPI algorithm relies on the fact that <q type="quote">all that is required for the policy improvement step is <gap desc="formula"/>.</q>  This allows <gap desc="formula"/> to be estimated at each iteration through simulation, avoiding the inhibitive computations in the policy evaluation step of the policy iteration algorithm (PIA).  In this sense, SBPI resembles MPIA, which can be described (in the average cost model) as follows (taken from Puterman, p.386):</p><list><item>1. Select <gap desc="formula"/>, specify <gap desc="formula"/>, and set <gap desc="formula"/>.</item><item>2. (Policy Improvement)  Choose <gap desc="formula"/> to satisfy<gap desc="formula"/>, setting <gap desc="formula"/> if possible.</item><item>3. (Partial Policy Evaluation)</item><item><list><item>a. Set <gap desc="formula"/>, and <gap desc="formula"/>.</item><item>b. If <gap desc="formula"/>, go to step 4.  Otherwise, to to (c).</item><item>c. If <gap desc="formula"/>, go to (e).  Otherwise, compute <gap desc="formula"/> by <gap desc="formula"/>.</item><item>d. Increment <i>k</i> by 1 and return to (c).</item><item>e. Set <gap desc="formula"/> and go to step 2.</item></list></item><item>4. Choose <gap desc="formula"/> and stop.</item></list><p>The two algorithms are similar in that they produce estimates (<gap desc="formula"/> in the case of SBPI and <gap desc="formula"/> in the case of MPIA) that are used in the evaluation (SBPI) and improvement (MPIA) steps, respectively.  Moreover, both have as stopping rules either a fixed number of approximations or <gap desc="formula"/>-optimality, or both.  I appreciated the comment in <i type="title">Convergence</i> that <q type="qutoe">we leave the analysis of stopping rules as a subject for future research.</q>  Indeed, the paper does not explicitly give stopping rules, but only shows that in order to ensure convergence, under specified conditions, that one must run simulations <i>at least </i>a certain number of iterations (Theorem 4.2).  The beauty of this result is its generality.  Perhaps a stopping rule could appear in the form of a minimum threshold for the number of iterations accompanied by the condition that <gap desc="formula"/>.</p><p>For simplicity's sake, I appreciated the Ratio Estimator given in section 5.3.  As the authors describe it, it <q type="quote">is perhaps the least complex to implement, as it can be applied based on a single simulated sample path.</q>  The estimator of <gap desc="formula"/>, where <gap desc="formula"/> represents the mean <q type="quote">cumulative centered cost until the end of the current regenerative cycle when the chain hits<gap desc="formula"/></q> given that the cycle began in state <i>x,</i> and where <gap desc="formula"/>.represents the mean number of visits to state x per regenerative cycle.  Proposition 5.9 claims that <gap desc="formula"/> as defined above is indeed an unbiased estimator for<gap desc="formula"/>, and that the sufficient conditions are met by virtue of the run lengths growing fast enough (ref. Proposition 5.5).  Then, using the Ratio Estimator (or either of the other two estimators mentioned in the paper), convergence is ensured for the bias and hence for the policy.  Again, however, a stopping rule for computing the <gap desc="formula"/> is not explicitly stated, leaving an open door for future research.</p><p>What I like about the paper, and the Ratio Estimator in particular, is that it shows how a computationally inhibitive MDP can be solved iteratively, in a finite (although perhaps very large) number of steps.  It is possible to code such a problem, and the assurance of convergence outlined herein makes SBPI an attractive alternative.  What I would like to know is how the convergence rate of SBPI compares with those of the actor-critic and MPI algorithms mentioned by the authors, as well as what constitutes a legitimate stopping rule in the computation of the <gap desc="formula"/>.</p></div><div type="closer"><p/></div></body></text></TEI.2>